{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Task: Detecting and Classifying Traffic Signs\n",
    "## Objective:\n",
    "### Use OpenCV to detect and classify traffic signs in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task:\n",
    "### ● Loading a data set\n",
    "### ○ You can use, for example, the German Traffic Sign Recognition Benchmark (GTSRB) as a data set.\n",
    "### ○ Load traffic sign images and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId   \n",
       "0     27      26       5       5      22      20       20  \\\n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./gtsrb/Train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes\n",
    "n_classes = df_train['ClassId'].nunique()\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.835880</td>\n",
       "      <td>50.328930</td>\n",
       "      <td>5.999515</td>\n",
       "      <td>5.962381</td>\n",
       "      <td>45.197302</td>\n",
       "      <td>44.728379</td>\n",
       "      <td>15.788390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.306933</td>\n",
       "      <td>23.115423</td>\n",
       "      <td>1.475493</td>\n",
       "      <td>1.385440</td>\n",
       "      <td>23.060157</td>\n",
       "      <td>21.971145</td>\n",
       "      <td>12.013238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Width        Height        Roi.X1        Roi.Y1        Roi.X2   \n",
       "count  39209.000000  39209.000000  39209.000000  39209.000000  39209.000000  \\\n",
       "mean      50.835880     50.328930      5.999515      5.962381     45.197302   \n",
       "std       24.306933     23.115423      1.475493      1.385440     23.060157   \n",
       "min       25.000000     25.000000      0.000000      5.000000     20.000000   \n",
       "25%       35.000000     35.000000      5.000000      5.000000     29.000000   \n",
       "50%       43.000000     43.000000      6.000000      6.000000     38.000000   \n",
       "75%       58.000000     58.000000      6.000000      6.000000     53.000000   \n",
       "max      243.000000    225.000000     20.000000     20.000000    223.000000   \n",
       "\n",
       "             Roi.Y2       ClassId  \n",
       "count  39209.000000  39209.000000  \n",
       "mean      44.728379     15.788390  \n",
       "std       21.971145     12.013238  \n",
       "min       20.000000      0.000000  \n",
       "25%       30.000000      5.000000  \n",
       "50%       38.000000     12.000000  \n",
       "75%       52.000000     25.000000  \n",
       "max      205.000000     42.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to images \n",
    "gtsrb_path = './gtsrb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(data_path, n_classes, target_size=(32, 32), test_size=0.2, random_state=42):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        class_path = os.path.join(data_path, '{0}'.format(i))\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "\n",
    "            # check if the file is an image\n",
    "            if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img = cv2.imread(image_path)\n",
    "\n",
    "                # resize the image\n",
    "                img = cv2.resize(img, target_size)\n",
    "\n",
    "                data.append(img)\n",
    "                labels.append(i)\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        data, labels, test_size = test_size, random_state = random_state)\n",
    "\n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and labels\n",
    "train_data, test_data, train_labels, test_labels = load_train_data(os.path.join(gtsrb_path, 'Train'), n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ● Image processing\n",
    "### ○ Apply image preprocessing such as conversion to greyscale, normalisation, and maybe binarisation.\n",
    "### ○ Use edge detection or other techniques to extract traffic signs from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTSRBDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            # tensor to PIL Image\n",
    "            img = transforms.ToPILImage()(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # back to PyTorch tensor\n",
    "        img = transforms.ToTensor()(img)\n",
    "\n",
    "        return {'image': img, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = cv2.convertScaleAbs(img) # to 8-bit\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR to RGB\n",
    "\n",
    "    # random rotation\n",
    "    angle = np.random.uniform(-25, 25)\n",
    "    rows, cols, _ = img_rgb.shape\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    img_rotated = cv2.warpAffine(img_rgb, rotation_matrix, (cols, rows))\n",
    "\n",
    "    # random horizontal flip\n",
    "    if np.random.rand() < 0.5:\n",
    "        img_rotated = cv2.flip(img_rotated, 1)\n",
    "    \n",
    "    # random vertical flip\n",
    "    if np.random.rand() < 0.5:\n",
    "        img_rotated = cv2.flip(img_rotated, 0)\n",
    "\n",
    "    # RGB back to BGR\n",
    "    img_bgr = cv2.cvtColor(img_rotated, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # grayscale\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    \n",
    "    # normalize to the range [0, 1]\n",
    "    normalized = (blurred - blurred.min()) / (blurred.max() - blurred.min())\n",
    "    \n",
    "    # brighten a image if nessessory \n",
    "    if np.mean(normalized) < 0.5:\n",
    "        brightness_factor = np.random.uniform(1.0, 2.0) \n",
    "        normalized = np.clip(normalized * brightness_factor, 0.0, 1.0)\n",
    "\n",
    "    tensor_image = torch.from_numpy(normalized).float()\n",
    "    \n",
    "    return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_data = [preprocess_image(image) for image in train_data]\n",
    "preprocessed_test_data = [preprocess_image(image) for image in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GTSRBDataset(preprocessed_train_data, train_labels, transform = None)\n",
    "test_dataset = GTSRBDataset(preprocessed_test_data, test_labels, transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 225\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GTSRB_CNN(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes, dropout_prob=0.25):\n",
    "        super(GTSRB_CNN, self).__init__()\n",
    "        # 1 conv\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.elu1 = nn.LeakyReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
    "        # 2 conv\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.elu2 = nn.LeakyReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
    "        # 3 conv\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.elu3 = nn.LeakyReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
    "        # 4 conv\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.elu4 = nn.LeakyReLU()\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
    "        # 1 fc\n",
    "        self.fc1 = nn.Linear(in_features=256 * 2 * 2, out_features=256)\n",
    "        self.elu5 = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1 conv\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.elu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        # 2 conv\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.elu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        # 3 conv\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.elu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        # 4 conv\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.elu4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        # 1 fc\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.elu5(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 1\n",
    "num_classes = 43\n",
    "model = GTSRB_CNN(num_channels=num_channels, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.0008)\n",
    "scheduler = optim.lr_scheduler.LinearLR(optimizer,start_factor=1.0,end_factor=0.5,total_iters=10)\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch['image'], batch['label']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.long()\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # update the learning rate\n",
    "        scheduler.step()\n",
    "        # accuracy and average loss for the epoch\n",
    "        accuracy = total_correct / total_samples\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, labels = batch['image'], batch['label']\n",
    "            labels = labels.long()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 2.2331, Accuracy: 36.15%\n",
      "Epoch [2/20], Loss: 1.0776, Accuracy: 65.05%\n",
      "Epoch [3/20], Loss: 0.7198, Accuracy: 76.68%\n",
      "Epoch [4/20], Loss: 0.5411, Accuracy: 82.36%\n",
      "Epoch [5/20], Loss: 0.4077, Accuracy: 86.51%\n",
      "Epoch [6/20], Loss: 0.3267, Accuracy: 89.20%\n",
      "Epoch [7/20], Loss: 0.2555, Accuracy: 91.64%\n",
      "Epoch [8/20], Loss: 0.2149, Accuracy: 93.05%\n",
      "Epoch [9/20], Loss: 0.1591, Accuracy: 95.03%\n",
      "Epoch [10/20], Loss: 0.1246, Accuracy: 96.10%\n",
      "Epoch [11/20], Loss: 0.0950, Accuracy: 97.22%\n",
      "Epoch [12/20], Loss: 0.0806, Accuracy: 97.71%\n",
      "Epoch [13/20], Loss: 0.0800, Accuracy: 97.70%\n",
      "Epoch [14/20], Loss: 0.0654, Accuracy: 98.13%\n",
      "Epoch [15/20], Loss: 0.0544, Accuracy: 98.47%\n",
      "Epoch [16/20], Loss: 0.0497, Accuracy: 98.63%\n",
      "Epoch [17/20], Loss: 0.0482, Accuracy: 98.61%\n",
      "Epoch [18/20], Loss: 0.0410, Accuracy: 98.96%\n",
      "Epoch [19/20], Loss: 0.0352, Accuracy: 99.08%\n",
      "Epoch [20/20], Loss: 0.0404, Accuracy: 98.81%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.22%\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
